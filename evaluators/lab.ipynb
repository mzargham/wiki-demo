{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the section types from the CSV file\n",
    "stdf = pd.read_csv(\"requirements_data/section_types.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead section</td>\n",
       "      <td>A concise summary of the article, never divide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Body sections</td>\n",
       "      <td>Main content of the article, divided into logi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Infobox</td>\n",
       "      <td>Right-aligned summary of key facts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>References</td>\n",
       "      <td>Section listing the sources cited in the article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>See also</td>\n",
       "      <td>Internal links to related English Wikipedia ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Further reading</td>\n",
       "      <td>Relevant books, articles, or other publication...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>External links</td>\n",
       "      <td>Relevant and appropriate websites not used as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Categories</td>\n",
       "      <td>Navigational boxes and categories at the end o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Notes</td>\n",
       "      <td>Additional information and explanations not pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name                                        description\n",
       "0     Lead section  A concise summary of the article, never divide...\n",
       "1    Body sections  Main content of the article, divided into logi...\n",
       "2          Infobox                 Right-aligned summary of key facts\n",
       "3       References   Section listing the sources cited in the article\n",
       "4         See also  Internal links to related English Wikipedia ar...\n",
       "5  Further reading  Relevant books, articles, or other publication...\n",
       "6   External links  Relevant and appropriate websites not used as ...\n",
       "7       Categories  Navigational boxes and categories at the end o...\n",
       "8            Notes  Additional information and explanations not pa..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to classify sections\n",
    "def classify_sections(section_outline: str):\n",
    "    # Define section type keywords for classification\n",
    "    section_keywords = {\n",
    "        \"Lead section\": [\"Introduction\", \"Overview\", \"Summary\"],\n",
    "        \"Body sections\": [\"Background\", \"Development\", \"Architecture\", \"Timeline\", \"Features\", \"Collaborations\", \"Model Structure\", \"Training Data\", \"Algorithms\", \"Techniques\"],\n",
    "        \"Infobox\": [\"Infobox\"],\n",
    "        \"References\": [\"References\", \"Citations\"],\n",
    "        \"See also\": [\"See also\", \"Related Articles\"],\n",
    "        \"Further reading\": [\"Further reading\"],\n",
    "        \"External links\": [\"External links\"],\n",
    "        \"Categories\": [\"Categories\"],\n",
    "        \"Notes\": [\"Notes\", \"Footnotes\"]\n",
    "    }\n",
    "    \n",
    "    # Split the outline into sections\n",
    "    sections = [line.strip(\"# \").strip() for line in section_outline.splitlines() if line.strip()]\n",
    "    \n",
    "    # Function to get section type\n",
    "    def get_section_type(section):\n",
    "        for section_type, keywords in section_keywords.items():\n",
    "            if any(keyword.lower() in section.lower() for keyword in keywords):\n",
    "                return section_type\n",
    "        return \"Body sections\"  # Default to body sections if no match is found\n",
    "    \n",
    "    # Get section types for each section\n",
    "    section_types = [get_section_type(section) for section in sections]\n",
    "    \n",
    "    return sections, section_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataframes from the CSV files\n",
    "rbsdf = pd.read_csv(\"requirements_data/requirements_by_section_type.csv\")\n",
    "rdf = pd.read_csv(\"requirements_data/section_level_requirements.csv\")\n",
    "\n",
    "# Join the dataframes on \"name\" ~ \"requirement name\"\n",
    "joined_df = pd.merge(rbsdf, rdf, left_on=\"requirement_name\", right_on=\"name\")\n",
    "\n",
    "# Drop the redundant 'name' column from rdf\n",
    "joined_df = joined_df.drop(columns=[\"name\"]).set_index(\"requirement_name\").T\n",
    "\n",
    "# add a new column called \"requirements_list\" that contains an empty list\n",
    "#joined_df[\"requirements_list\"] = [[] for _ in range(len(joined_df))]\n",
    "\n",
    "cols = joined_df.columns\n",
    "criteria = joined_df.iloc[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>criteria_details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title format</td>\n",
       "      <td>Sentence case for titles and headings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consistency</td>\n",
       "      <td>Consistent style within an article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>References included</td>\n",
       "      <td>All statements must be supported by reliable s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead summary</td>\n",
       "      <td>Lead must summarize the article concisely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Infobox usage</td>\n",
       "      <td>Infobox must be right-aligned and summarize ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>External links relevance</td>\n",
       "      <td>External links must be relevant and appropriate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Further reading selectivity</td>\n",
       "      <td>Further reading section must be selective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>See also relevance</td>\n",
       "      <td>See also links must be directly related to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Category placement</td>\n",
       "      <td>Categories must be placed at the very end of t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  \\\n",
       "0                 Title format   \n",
       "1                  Consistency   \n",
       "2          References included   \n",
       "3                 Lead summary   \n",
       "4                Infobox usage   \n",
       "5     External links relevance   \n",
       "6  Further reading selectivity   \n",
       "7           See also relevance   \n",
       "8           Category placement   \n",
       "\n",
       "                                    criteria_details  \n",
       "0              Sentence case for titles and headings  \n",
       "1                 Consistent style within an article  \n",
       "2  All statements must be supported by reliable s...  \n",
       "3          Lead must summarize the article concisely  \n",
       "4  Infobox must be right-aligned and summarize ke...  \n",
       "5    External links must be relevant and appropriate  \n",
       "6          Further reading section must be selective  \n",
       "7  See also links must be directly related to the...  \n",
       "8  Categories must be placed at the very end of t...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>requirement_name</th>\n",
       "      <th>Lead section</th>\n",
       "      <th>Body sections</th>\n",
       "      <th>Infobox</th>\n",
       "      <th>References</th>\n",
       "      <th>See also</th>\n",
       "      <th>Further reading</th>\n",
       "      <th>External links</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title format</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consistency</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>References included</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead summary</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Infobox usage</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>External links relevance</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Further reading selectivity</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>See also relevance</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Category placement</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              requirement_name  Lead section  Body sections  Infobox  \\\n",
       "0                 Title format             1              1        0   \n",
       "1                  Consistency             1              1        1   \n",
       "2          References included             1              1        0   \n",
       "3                 Lead summary             1              0        0   \n",
       "4                Infobox usage             0              0        1   \n",
       "5     External links relevance             0              0        0   \n",
       "6  Further reading selectivity             0              0        0   \n",
       "7           See also relevance             0              0        0   \n",
       "8           Category placement             0              0        0   \n",
       "\n",
       "   References  See also  Further reading  External links  Categories  Notes  \n",
       "0           0         0                0               0           0      0  \n",
       "1           1         1                1               1           1      1  \n",
       "2           1         0                0               0           0      0  \n",
       "3           0         0                0               0           0      0  \n",
       "4           0         0                0               0           0      0  \n",
       "5           0         0                0               1           0      0  \n",
       "6           0         0                1               0           0      0  \n",
       "7           0         1                0               0           0      0  \n",
       "8           0         0                0               0           1      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lead section</th>\n",
       "      <th>Body sections</th>\n",
       "      <th>Infobox</th>\n",
       "      <th>References</th>\n",
       "      <th>See also</th>\n",
       "      <th>Further reading</th>\n",
       "      <th>External links</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Notes</th>\n",
       "      <th>criteria_details</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>requirement_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Title format</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentence case for titles and headings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consistency</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Consistent style within an article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>References included</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>All statements must be supported by reliable s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lead summary</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lead must summarize the article concisely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Infobox usage</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Infobox must be right-aligned and summarize ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>External links relevance</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>External links must be relevant and appropriate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Further reading selectivity</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Further reading section must be selective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>See also relevance</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>See also links must be directly related to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category placement</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Categories must be placed at the very end of t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Lead section Body sections Infobox References  \\\n",
       "requirement_name                                                            \n",
       "Title format                           1             1       0          0   \n",
       "Consistency                            1             1       1          1   \n",
       "References included                    1             1       0          1   \n",
       "Lead summary                           1             0       0          0   \n",
       "Infobox usage                          0             0       1          0   \n",
       "External links relevance               0             0       0          0   \n",
       "Further reading selectivity            0             0       0          0   \n",
       "See also relevance                     0             0       0          0   \n",
       "Category placement                     0             0       0          0   \n",
       "\n",
       "                            See also Further reading External links  \\\n",
       "requirement_name                                                      \n",
       "Title format                       0               0              0   \n",
       "Consistency                        1               1              1   \n",
       "References included                0               0              0   \n",
       "Lead summary                       0               0              0   \n",
       "Infobox usage                      0               0              0   \n",
       "External links relevance           0               0              1   \n",
       "Further reading selectivity        0               1              0   \n",
       "See also relevance                 1               0              0   \n",
       "Category placement                 0               0              0   \n",
       "\n",
       "                            Categories Notes  \\\n",
       "requirement_name                               \n",
       "Title format                         0     0   \n",
       "Consistency                          1     1   \n",
       "References included                  0     0   \n",
       "Lead summary                         0     0   \n",
       "Infobox usage                        0     0   \n",
       "External links relevance             0     0   \n",
       "Further reading selectivity          0     0   \n",
       "See also relevance                   0     0   \n",
       "Category placement                   1     0   \n",
       "\n",
       "                                                              criteria_details  \n",
       "requirement_name                                                                \n",
       "Title format                             Sentence case for titles and headings  \n",
       "Consistency                                 Consistent style within an article  \n",
       "References included          All statements must be supported by reliable s...  \n",
       "Lead summary                         Lead must summarize the article concisely  \n",
       "Infobox usage                Infobox must be right-aligned and summarize ke...  \n",
       "External links relevance       External links must be relevant and appropriate  \n",
       "Further reading selectivity          Further reading section must be selective  \n",
       "See also relevance           See also links must be directly related to the...  \n",
       "Category placement           Categories must be placed at the very end of t...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = joined_df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sentence case for titles and headings',\n",
       "       'Consistent style within an article',\n",
       "       'All statements must be supported by reliable sources',\n",
       "       'Lead must summarize the article concisely',\n",
       "       'Infobox must be right-aligned and summarize key facts',\n",
       "       'External links must be relevant and appropriate',\n",
       "       'Further reading section must be selective',\n",
       "       'See also links must be directly related to the article content',\n",
       "       'Categories must be placed at the very end of the article'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteria.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_requirements(section_type):\n",
    "    requirements = \"This section contains the following requirements:\\n\"\n",
    "    for r in rows:\n",
    "        if r == section_type:\n",
    "            for c in cols:\n",
    "                if joined_df.loc[r][c] == 1:\n",
    "                    crit = criteria[c]\n",
    "                    requirements += f\"- {crit}\\n\"\n",
    "    return requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This section contains the following requirements:\\n- Sentence case for titles and headings\\n- Consistent style within an article\\n- All statements must be supported by reliable sources\\n- Lead must summarize the article concisely\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump_requirements(\"Lead section\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outline(path):\n",
    "    # Read the outline from the file\n",
    "    with open(path, \"r\") as file:\n",
    "        text = file.read()\n",
    "        outline, sections = identify_sections(text, level=1)\n",
    "\n",
    "    return outline, sections\n",
    "\n",
    "def identify_sections(text, level=1):\n",
    "    # Identify the sections\n",
    "    sections = text[2:].split(\"\\n\"+level*\"#\"+\" \")\n",
    "    names = [section.split(\"\\n\")[0] for section in sections]\n",
    "    return names, sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../outputs/Llama_3_(Language_Model)/storm_gen_article_polished.txt\"\n",
    "article = path.split(\"/\")[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama_3_(Language_Model)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline, sections=get_outline(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['summary', 'Development', 'Architecture', 'Performance', 'Applications', 'Limitations', 'Reception', 'Future Prospects']\n"
     ]
    }
   ],
   "source": [
    "print(outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"summary\\n\\nLlama 3, developed by Meta, is a state-of-the-art large language model that signifies a major leap forward in the realm of artificial intelligence. Building on the successes of its predecessors, Llama 3 emphasizes ethical AI practices and community involvement through an open-source development strategy. This model stands out due to its enhanced capabilities, stemming from extensive training on a massive dataset of over 15 trillion tokens, which is seven times larger than that of Llama 2. This expansive dataset includes a rich variety of languages and code, ensuring broad applicability and robust performance across diverse tasks.\\nA crucial element of Llama 3’s development is its commitment to safety and appropriateness in content generation. Meta employs a combination of manual content reviews, automated checks, and iterative feedback mechanisms to maintain the model’s reliability and ethical standards. These measures are vital for ensuring that Llama 3's outputs are suitable for various applications, ranging from education and healthcare to content creation and translation. The model's open-source nature not only accelerates innovation but also democratizes access to cutting-edge AI technology, enabling a wider community to contribute to its development and utilize its capabilities.\\nArchitecturally, Llama 3 retains a decoder-only model structure but incorporates significant enhancements such as a new 128k tokenizer and optimized matrix multiplication kernels for x86 and ARM CPUs. These improvements, coupled with advanced training techniques like data parallelization and model parallelization, contribute to Llama 3's superior performance. The model excels in various benchmarks, outperforming both open-source and proprietary models in tasks like language understanding, reasoning, and code generation. The 70 billion parameter version, in particular, matches the performance of leading proprietary models, underscoring Llama 3's competitive edge in the AI landscape.\\nDespite its advancements, Llama 3 is not without limitations. Issues such as overfitting, ethical concerns, and the substantial computational resources required for training remain significant challenges. Ensuring high-quality, diverse datasets for training and fine-tuning is critical to maintaining the model's performance and reliability. As the AI community continues to explore and address these challenges, the future of Llama 3 looks promising with potential enhancements and broader applications on the horizon. Meta’s open-source approach and commitment to ethical AI practices position Llama 3 as a pivotal model in the ongoing evolution of artificial intelligence technology.\\n\", \"Development\\n\\nLlama 3 represents a significant advancement in the development of large language models, with a strong focus on community involvement and ethical AI practices. Meta, the company behind Llama 3, has adopted an open-source approach to enable a broader community to contribute to and build upon the Llama models. This strategy not only accelerates innovation but also ensures that the benefits of AI advancements are widely distributed [1].\\nA critical aspect of the development process is maintaining the safety and appropriateness of the content generated by Llama 3. To achieve this, Meta employs several methods, including manual content review, automated checks for problematic topics or words, and iterative feedback to continually improve the model [2]. These measures are essential to ensure that the model's outputs remain safe and suitable for various applications.\\nThe development strategy also involves eliminating bottlenecks associated with data management. Meta focuses on building and managing high-quality datasets for training, fine-tuning, evaluation, and monitoring. This approach is vital for developing impactful AI applications and has been shared with organizations in various stages of their processes [3]. For example, Label Studio is used for data annotation and preparation, while Colab T4 instances are utilized for fine-tuning processes, demonstrating a structured and iterative development workflow [4].\\nIn addition to technical advancements, Llama 3's development emphasizes practical applications across multiple industries. Organizations in education, video communications, research, and medicine are leveraging Llama 3 to create localized educational content, summarize video calls, and provide medical information in low-resource settings [5]. This wide range of applications highlights the model's versatility and its potential to address real-world challenges.\\nFurthermore, Meta has introduced significant breakthroughs with Llama 2 that continue to influence Llama 3. The Llama 2 models overcame the tradeoff between safety and helpfulness by training two distinct reward models: the Helpfulness RM and the Safety RM. These models optimize for different criteria, thereby achieving superior performance in both areas. The architecture and hyper-parameters remain consistent with previous models, with adjustments made to the classification head for next-token prediction, which is replaced with a regression head for generating scalar rewards [6].\\n\", \"Architecture\\n\\nThe Llama 3 architecture is fundamentally built on a decoder-only model, incorporating a newly developed 128k tokenizer, which marks a significant upgrade given that most large language models tend to reuse existing tokenizers[7]. This new tokenizer contributes to substantial performance gains, differentiating Llama 3 from its predecessors and competitors.\\nIn terms of data scale, Llama 3 has been pre-trained on over 15 trillion tokens, sourced from publicly available data, which is seven times larger than the dataset used for Llama 2[8]. This dataset includes four times more code and over 5% high-quality, non-English data covering more than 30 languages[8]. These enhancements in data volume and diversity are central to the model's improved performance.\\nOptimization techniques such as data parallelization, model parallelization, and pipeline parallelization were employed to streamline the training process[8]. Meta also developed a new advanced training stack to maximize GPU uptime, automating error detection, handling, and maintenance[8].\\nWhile architecturally similar to its predecessor, the Llama 3 model supports a larger context window, highlighting improvements primarily driven by data quality, data size, and enhanced training methodologies rather than drastic architectural changes[8]. The grouped query attention mechanism, which was present in Llama 2, has been further optimized for the larger models in Llama 3, contributing to its performance enhancements[7].\\nA notable innovation in Llama 3 includes the introduction of new optimized matrix multiplication kernels for x86 and ARM CPUs, which improve prompt evaluation performance for FP16 and 8-bit quantized data types[9]. Despite the foundational architecture remaining largely unchanged from LLaMA-1 models, the use of 40% more data for training underpins the significant advancements observed in Llama 3[9].\\n\", \"Performance\\n\\nLlama 3 demonstrates exceptional performance across various benchmarks, solidifying its status as a leading language model in the industry. It shows continuous log-linear improvement after training on up to 15 trillion tokens, surpassing the performance of models trained on significantly less data, such as an 8 billion parameter model with a Chinchilla-optimal training compute corresponding to approximately 200 billion tokens[8].\\nThe 8 billion (8B) and 70 billion (70B) parameter versions of Llama 3 outperform other open-source models like Mistral 7B and Google's Gemma 7B on standard benchmarks including MMLU (Massive Multitask Language Understanding), ARC, DROP, GPQA, HumanEval, GSM-8K, MATH, AGIEval, and BIG-Bench Hard[3]. Llama 3's 70B model, in particular, showcases the best overall performance score, matching that of the most powerful proprietary models such as Gemini Pro 1.5 and Claude 3 Sonnet[10].\\nThe superior performance of Llama 3 can be attributed to several key factors. First, the pretraining process involved utilizing seven times more data than its predecessor, Llama 2, and careful curation of instruction-tuning data to enhance alignment and output quality[11]. Additionally, both the 8B and 70B models employ Grouped-Query Attention (GQA) for improved inference scalability, further contributing to their robust performance[12].\\nWhen it comes to user experience, Llama 3 has also shown improved attention mechanisms compared to previous models. Evaluations conducted exclusively on 70B models revealed that the Llama 3 Chat model outperforms other open-source models by a significant margin (60–75%) on both single-turn and multi-turn prompts, and is comparable to ChatGPT[6].\\nThe architecture of Llama 3 remains largely unchanged from LLaMA-1 models, but the inclusion of 40% more training data for the foundational models has also played a critical role in enhancing performance. Future releases may include a 34B parameter model upon meeting safety targets[9].\\n\", \"Applications\\n\\nLlama 3 is a versatile language model with a broad range of applications across various domains. Its advanced capabilities in text generation, conversation, summarization, and translation make it a valuable tool for numerous industries.\\n\\n## Content Creation and Translation\\n\\nOne of the primary applications of Llama 3 is content creation. The model's ability to generate coherent and contextually appropriate text makes it suitable for tasks such as writing articles, crafting stories, and creating marketing content. Additionally, Llama 3 excels in translation, offering robust support for multiple languages, which facilitates global communication and content localization[2][13].\\n\\n## Integration with Meta Products\\n\\nLlama 3 seamlessly integrates with other Meta products and services, streamlining workflows and enhancing data exchange within existing infrastructures[14]. This integration capability makes it a useful component in a unified and collaborative environment, improving efficiency and productivity.\\n\\n## Mobile Experience Enhancement\\n\\nThrough a partnership with Qualcomm, Llama 3 is optimized for Snapdragon platforms, thereby enhancing mobile experiences with on-device learning and direct content generation capabilities. This optimization makes advanced AI features more accessible on mobile devices, broadening the scope of Llama 3's applications[15].\\n\\n## Industry-Specific Solutions\\n\\nLlama 3's adaptability extends to specific industry needs. For example, in the healthcare sector, the model can be fine-tuned using domain-specific datasets, such as medical records, to enhance its proficiency in medical Q&A applications[16]. This adaptability ensures that Llama 3 can provide accurate and contextually relevant information across various professional fields.\\n\\n## Educational and Research Support\\n\\nOrganizations are leveraging Llama 3 to make educational content more localized and accessible to students. Additionally, the model is used to summarize video calls, making it a useful tool for educational and research purposes[5]. The capability to understand and process extensive text up to 2,048 words long allows Llama 3 to handle complex ideas and arguments, facilitating deeper insights and understanding[2].\\n\\n## Open Source and Community Contributions\\n\\nLlama 3's open-source nature enables a broader community to contribute to and build upon its capabilities. This approach accelerates innovation and ensures that the benefits of AI advancements are widely distributed. Meta's commitment to ethical AI development and fostering community collaboration suggests a future roadmap focused on both technological breakthroughs and user-friendliness[1].\\n\", \"Limitations\\n\\nDespite its numerous advancements, Llama 3 faces several limitations that need to be addressed to enhance its applicability and reliability.\\n\\n## Overfitting and Data Dependence\\n\\nOne significant issue with Llama 3, as with many large language models, is the risk of overfitting to its training data. This occurs when the model performs exceptionally well on training data but fails to generalize effectively to unseen data, potentially limiting its robustness and applicability across diverse tasks and datasets[17].\\n\\n## Ethical and Reliability Concerns\\n\\nThe ethical implications of deploying Llama 3 in real-world scenarios remain a critical concern. Ensuring that the model engages with content ethically and avoids harmful actions is a substantial challenge. Balancing technological advancements with ethical responsibilities is crucial for harnessing AI's full potential for societal betterment[18]. Furthermore, in fields like medical information, the stakes for accuracy and reliability are even higher, as misinformation can lead to significant real-world health risks[4].\\n\\n## Computational Resources and Efficiency\\n\\nTraining and fine-tuning large language models like Llama 3 demand substantial computational resources. Although improvements in hardware reliability and scalable storage systems have enhanced training efficiencies, the computational cost remains a barrier for widespread adoption and experimentation by smaller organizations and individual researchers[8][16].\\n\\n## Dataset Quality and Curation\\n\\nThe quality of the training and fine-tuning datasets is pivotal for the model's performance. While Llama 3 has been trained on a significantly larger dataset compared to its predecessors, the curation of this data poses a substantial challenge. Ensuring that the data is diverse and representative without including redundant or low-quality information is essential for maintaining and improving the model's performance[3]. Missteps in data curation could lead to biased or incorrect model outputs, which are especially problematic in sensitive applications like medical Q&A[4].\\n\\n## Evaluation Challenges\\n\\nEvaluating large language models accurately is challenging due to the massive datasets involved and the nuanced nature of human language. Traditional metrics like perplexity might not fully capture a model's performance, especially as the risk of inadvertently including portions of test sets in the training data increases with larger corpora[17].\\n\", \"Reception\\n\\nThe reception of Llama 3, Meta's latest language model, has been overwhelmingly positive across various sectors. The model has been praised for its significant advancements in efficiency and capability over its predecessors. Llama 3 has demonstrated improved attention mechanisms and alignment, resulting in a more nuanced understanding and generation of responses. Enhancements in reasoning and code generation are also notable, contributing to a diverse range of model responses and reduced false refusal rates [8].\\nIn the AI research community, Llama 3 has outperformed open-source models by a significant margin, particularly in single-turn and multi-turn prompts, showing comparable results to ChatGPT [6]. This performance has been bolstered by rigorous evaluation methods, including the use of a 7-point Likert scale for answer quality assessment and the calculation of inter-rater reliability (IRR) to ensure consistency [6].\\nIndustries ranging from education to healthcare have leveraged Llama 3 for various applications. For instance, the model has been used to localize educational content for students, summarize video communications, and provide medical information in low-resource settings [5]. The flexibility and power of Llama 3 have also been highlighted in its use for enhancing financial forecasting, healthcare analytics, and retail optimization through predictive modeling and user-friendly interfaces [19].\\nThe release of Llama 3 has sparked a competitive atmosphere in the AI landscape, with other tech giants like Google potentially poised to respond with their advancements. This competition is viewed as beneficial for the broader AI community, driving innovation and efficiency across the field [14].\\nAdditionally, Meta's commitment to open-source development and ethical AI practices has been a significant factor in the positive reception of Llama 3. By making the model available under an open license, Meta has enabled a broader community to contribute and build upon its advancements, ensuring that the benefits of AI are widely distributed [6][1]. Integrations with content safety features, such as those available through Azure AI Content Safety, further ensure that the model's applications adhere to responsible AI practices [20].\\n\", \"Future Prospects\\n\\nThe future of Llama 3 looks promising with several exciting developments on the horizon. One of the key aspects of Llama 3's future is its open-source nature, which not only accelerates innovation by enabling a broader community to contribute and build upon the models but also ensures that the benefits of AI advancements are widely distributed[1]. This open-source strategy reflects Meta's commitment to fostering community and collaboration, which is as crucial as the technological breakthroughs themselves.\\nAs we advance, ethical considerations surrounding the behavior of models like Llama 3 will become increasingly paramount. Ensuring these models engage with complex content ethically while avoiding harmful actions is a significant challenge[18]. Balancing these ethical responsibilities with technological advancements will be crucial in harnessing the full potential of AI for societal betterment. Efficient data management will also play a critical role in this regard, as it is essential for training, fine-tuning, and leveraging large language models effectively[18].\\nThe anticipated release of Llama 3 has generated considerable excitement, particularly with Meta Vice President Nick Clegg confirming its imminent launch[21]. Alongside Llama 3, Meta is integrating virtual assistant features into platforms like Facebook and WhatsApp, which are based on the Llama 3 model[9]. This integration exemplifies the broader applicability and utility of Llama 3 across various services and platforms.\\nThe development strategy for Llama 3 includes the use of resources such as the Data Curation Notebook and the Fine-tuning Notebook, designed to streamline the workflow and enhance the practical application of the model[4]. This structured, iterative development approach ensures continuous improvement and adaptation of Llama 3 for specific use cases, such as medical Q&A, through systematic evaluation and refinement.\\nMoreover, Llama 3 has shown exceptional performance, particularly the 70B model, which matches the performance of some of the most powerful proprietary models like Gemini Pro 1.5 and Claude 3 Sonnet[10]. This superior performance on benchmarks like the Massive Multitask Language Understanding (MMLU) highlights Llama 3's capability to understand and perform a wide range of tasks effectively.\"]\n"
     ]
    }
   ],
   "source": [
    "print(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"I am writing a wikipedia article called \"+article+\" and I am working the \"+s+\" section. Please provide a draft of the section according the wikipedia style guidelines\" for s in outline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: rewrite the below to use the stdf instead of the section_keywords\n",
    "section_keywords = {\n",
    "    \"Lead section\": [\"Introduction\", \"Overview\", \"Summary\"],\n",
    "    \"Body sections\": [\"Background\", \"Development\", \"Architecture\", \"Timeline\", \"Features\", \"Collaborations\", \"Model Structure\", \"Training Data\", \"Algorithms\", \"Techniques\"],\n",
    "    \"Infobox\": [\"Infobox\"],\n",
    "    \"References\": [\"References\", \"Citations\"],\n",
    "    \"See also\": [\"See also\", \"Related Articles\"],\n",
    "    \"Further reading\": [\"Further reading\"],\n",
    "    \"External links\": [\"External links\"],\n",
    "    \"Categories\": [\"Categories\"],\n",
    "    \"Notes\": [\"Notes\", \"Footnotes\"]\n",
    "    }\n",
    "def get_section_type(section):\n",
    "    for section_type, keywords in section_keywords.items():\n",
    "        if any(keyword.lower() in section.lower() for keyword in keywords):\n",
    "            return section_type\n",
    "    return \"Body sections\" # Default to body sections if no match is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_types = [get_section_type(section) for section in sections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_guidelines = [\"The section \"+s+\" is a \"+get_section_type(s)+\" section. \"+dump_requirements(get_section_type(s)) for s in outline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The section summary is a Lead section section. This section contains the following requirements:\\n- Sentence case for titles and headings\\n- Consistent style within an article\\n- All statements must be supported by reliable sources\\n- Lead must summarize the article concisely\\n', 'The section Development is a Body sections section. This section contains the following requirements:\\n- Sentence case for titles and headings\\n- Consistent style within an article\\n- All statements must be supported by reliable sources\\n', 'The section Architecture is a Body sections section. This section contains the following requirements:\\n- Sentence case for titles and headings\\n- Consistent style within an article\\n- All statements must be supported by reliable sources\\n', 'The section Performance is a Body sections section. This section contains the following requirements:\\n- Sentence case for titles and headings\\n- Consistent style within an article\\n- All statements must be supported by reliable sources\\n', 'The section Applications is a Body sections section. This section contains the following requirements:\\n- Sentence case for titles and headings\\n- Consistent style within an article\\n- All statements must be supported by reliable sources\\n', 'The section Limitations is a Body sections section. This section contains the following requirements:\\n- Sentence case for titles and headings\\n- Consistent style within an article\\n- All statements must be supported by reliable sources\\n', 'The section Reception is a Body sections section. This section contains the following requirements:\\n- Sentence case for titles and headings\\n- Consistent style within an article\\n- All statements must be supported by reliable sources\\n', 'The section Future Prospects is a Body sections section. This section contains the following requirements:\\n- Sentence case for titles and headings\\n- Consistent style within an article\\n- All statements must be supported by reliable sources\\n']\n"
     ]
    }
   ],
   "source": [
    "print(question_guidelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_guidelines = [\n",
    "    \"Evaluate based on the wikipedia style guidelines.\",\n",
    "    \"Provide informative feedback on the response that will help the editors improve the article.\",\n",
    "    \"Provide a Grade in the range 0-100.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"../profbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/z/Documents/GitHub/profbot'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exam import Exam, GradeLog\n",
    "from llmtest import Llm, LLMTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Exam(questions, question_guidelines, exam_guidelines, GradeLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_llm = Llm(model_identifier=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gpt-4o', 'messages': [{'role': 'user', 'content': 'this is a test; please respond with quip'}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Testing, testing—one, two, three! If this were a real emergency, I'd be a lot wittier.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_llm.prompt(\"this is a test; please respond with quip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lookup:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.model_identifier = \"lookup\"\n",
    "        \n",
    "    def prompt_sequence(self,questions):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = LLMTest(Lookup(sections), eval_llm, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llmtest.LLMTest at 0x7fabb84111f0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "g= ex.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Section Name\"] = df.Prompt.apply(lambda x: x.split(\"working the \")[1].split(\" section.\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"Section Name\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA</th>\n",
       "      <th>Student</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Response</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Section Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>lookup</td>\n",
       "      <td>I am writing a wikipedia article called Llama_...</td>\n",
       "      <td>summary\\n\\nLlama 3, developed by Meta, is a st...</td>\n",
       "      <td>### \\n\\n### Notes:\\n\\n#### Positive Aspects:\\n...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Development</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>lookup</td>\n",
       "      <td>I am writing a wikipedia article called Llama_...</td>\n",
       "      <td>Development\\n\\nLlama 3 represents a significan...</td>\n",
       "      <td>### \\n\\n### Notes:\\n\\n#### Positive Aspects:\\n...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Architecture</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>lookup</td>\n",
       "      <td>I am writing a wikipedia article called Llama_...</td>\n",
       "      <td>Architecture\\n\\nThe Llama 3 architecture is fu...</td>\n",
       "      <td>### \\n\\n### Notes:\\n\\n#### Positive Aspects:\\n...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Performance</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>lookup</td>\n",
       "      <td>I am writing a wikipedia article called Llama_...</td>\n",
       "      <td>Performance\\n\\nLlama 3 demonstrates exceptiona...</td>\n",
       "      <td>### \\n\\n### Notes:\\n\\n#### Positive Aspects:\\n...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Applications</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>lookup</td>\n",
       "      <td>I am writing a wikipedia article called Llama_...</td>\n",
       "      <td>Applications\\n\\nLlama 3 is a versatile languag...</td>\n",
       "      <td>### \\n\\n### Notes:\\n\\n#### Positive Aspects:\\n...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Limitations</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>lookup</td>\n",
       "      <td>I am writing a wikipedia article called Llama_...</td>\n",
       "      <td>Limitations\\n\\nDespite its numerous advancemen...</td>\n",
       "      <td>### \\n\\n### Notes:\\n\\n#### Positive Aspects:\\n...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reception</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>lookup</td>\n",
       "      <td>I am writing a wikipedia article called Llama_...</td>\n",
       "      <td>Reception\\n\\nThe reception of Llama 3, Meta's ...</td>\n",
       "      <td>### \\n\\n### Notes:\\n\\n#### Positive Aspects:\\n...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Future Prospects</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>lookup</td>\n",
       "      <td>I am writing a wikipedia article called Llama_...</td>\n",
       "      <td>Future Prospects\\n\\nThe future of Llama 3 look...</td>\n",
       "      <td>### \\n\\n### Notes:\\n\\n#### Positive Aspects:\\n...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      TA Student  \\\n",
       "Section Name                       \n",
       "summary           gpt-4o  lookup   \n",
       "Development       gpt-4o  lookup   \n",
       "Architecture      gpt-4o  lookup   \n",
       "Performance       gpt-4o  lookup   \n",
       "Applications      gpt-4o  lookup   \n",
       "Limitations       gpt-4o  lookup   \n",
       "Reception         gpt-4o  lookup   \n",
       "Future Prospects  gpt-4o  lookup   \n",
       "\n",
       "                                                             Prompt  \\\n",
       "Section Name                                                          \n",
       "summary           I am writing a wikipedia article called Llama_...   \n",
       "Development       I am writing a wikipedia article called Llama_...   \n",
       "Architecture      I am writing a wikipedia article called Llama_...   \n",
       "Performance       I am writing a wikipedia article called Llama_...   \n",
       "Applications      I am writing a wikipedia article called Llama_...   \n",
       "Limitations       I am writing a wikipedia article called Llama_...   \n",
       "Reception         I am writing a wikipedia article called Llama_...   \n",
       "Future Prospects  I am writing a wikipedia article called Llama_...   \n",
       "\n",
       "                                                           Response  \\\n",
       "Section Name                                                          \n",
       "summary           summary\\n\\nLlama 3, developed by Meta, is a st...   \n",
       "Development       Development\\n\\nLlama 3 represents a significan...   \n",
       "Architecture      Architecture\\n\\nThe Llama 3 architecture is fu...   \n",
       "Performance       Performance\\n\\nLlama 3 demonstrates exceptiona...   \n",
       "Applications      Applications\\n\\nLlama 3 is a versatile languag...   \n",
       "Limitations       Limitations\\n\\nDespite its numerous advancemen...   \n",
       "Reception         Reception\\n\\nThe reception of Llama 3, Meta's ...   \n",
       "Future Prospects  Future Prospects\\n\\nThe future of Llama 3 look...   \n",
       "\n",
       "                                                              Notes  Grade  \n",
       "Section Name                                                                \n",
       "summary           ### \\n\\n### Notes:\\n\\n#### Positive Aspects:\\n...     75  \n",
       "Development       ### \\n\\n### Notes:\\n\\n#### Positive Aspects:\\n...     80  \n",
       "Architecture      ### \\n\\n### Notes:\\n\\n#### Positive Aspects:\\n...     85  \n",
       "Performance       ### \\n\\n### Notes:\\n\\n#### Positive Aspects:\\n...     85  \n",
       "Applications      ### \\n\\n### Notes:\\n\\n#### Positive Aspects:\\n...     80  \n",
       "Limitations       ### \\n\\n### Notes:\\n\\n#### Positive Aspects:\\n...     85  \n",
       "Reception         ### \\n\\n### Notes:\\n\\n#### Positive Aspects:\\n...     85  \n",
       "Future Prospects  ### \\n\\n### Notes:\\n\\n#### Positive Aspects:\\n...     80  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### \n",
      "\n",
      "### Notes:\n",
      "\n",
      "#### Positive Aspects:\n",
      "\n",
      "1. **Conciseness and Comprehensiveness:**\n",
      "   - The summary is concise and comprehensive, encapsulating various aspects of Llama 3, including its development, capabilities, ethical considerations, and architectural specifics.\n",
      "\n",
      "2. **Structured Information:**\n",
      "   - The response is well-structured, detailing different facets such as ethics, community involvement, and technical enhancements in a systematic manner.\n",
      "\n",
      "3. **Clarity:**\n",
      "   - The language is clear, and the information is well-presented, making it easy to understand the key points about Llama 3.\n",
      "\n",
      "#### Areas for Improvement:\n",
      "\n",
      "1. **Sentence Case for Titles and Headings:**\n",
      "   - According to Wikipedia style guidelines, titles and headings should use sentence case. Your title \"summary\" should be corrected to \"Summary.\"\n",
      "\n",
      "2. **Citation of Reliable Sources:**\n",
      "   - The summary lacks citations for the stated facts. In Wikipedia articles, it’s essential to back up every claim with reliable sources. Ensure you add references to support the statistics and claims mentioned (e.g., the size of the dataset, comparisons with other models).\n",
      "\n",
      "3. **Consistency in Style:**\n",
      "   - Ensure there is a consistent style within the article. For example, the phrase \"Llama 3’s development\" should be standardized (apostrophe usage) throughout the text.\n",
      "\n",
      "4. **Neutral Point of View:**\n",
      "   - Some phrases, like \"state-of-the-art\" and \"major leap forward,\" may come off as overly promotional. Wikipedia articles should maintain a neutral tone. Consider replacing these with more neutral phrasing (e.g., \"Llama 3 is a large language model developed by Meta that builds on the advancements of its predecessors.\").\n",
      "\n",
      "5. **Lead Section Requirements:**\n",
      "   - The lead should summarize the most important aspects of the article concisely. Ensure that it doesn't delve too deeply into technical aspects that should be elaborated on in the main body. For instance, the specifics about the tokenizer and performance benchmarks might be more appropriate in a dedicated section rather than in the lead.\n",
      "\n",
      "6. **Readability:**\n",
      "   - Break down complex sentences for better readability. For instance, \"Meta employs a combination of manual content reviews, automated checks, and iterative feedback mechanisms to maintain the model’s reliability and ethical standards,\" could be simplified for better flow.\n",
      "\n",
      "#### Example of Improved Lead Section:\n",
      "```\n",
      "Summary\n",
      "\n",
      "Llama 3, developed by Meta, is a large language model that emphasizes ethical AI practices and community involvement through an open-source development strategy. Building on the successes of its predecessors, Llama 3 has enhanced capabilities from extensive training on a dataset of over 15 trillion tokens, including a variety of languages and code. Meta focuses on safety and appropriateness in content generation through manual reviews, automated checks, and feedback mechanisms.\n",
      "\n",
      "The model's open-source nature accelerates innovation and democratizes access to AI technology. Architecturally, Llama 3 retains a decoder-only structure with enhancements like a new 128k tokenizer and optimized kernels for CPUs. Despite advancements, challenges such as overfitting and substantial computational requirements persist. Meta’s approach positions Llama 3 as a significant model in AI technology's evolution.\n",
      "\n",
      "(Ensure to add appropriate citations to support your statements.)\n",
      "```\n",
      "\n",
      "### Summary:\n",
      "Good job on creating a comprehensive and well-structured summary. Focus on ensuring adherence to Wikipedia's style guidelines, especially regarding citation of sources, neutral tone, and sentence case for titles and headings. With these improvements, your article will better align with Wikipedia’s standards.\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0].Notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am writing a wikipedia article called Llama_3_(Language_Model) and I am working the summary section. Please provide a draft of the section according the wikipedia style guidelens\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0].Prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
